---
title: "ã€MediaPipeã€‘äººç‰©ç”»åƒã‚’åˆ‡ã‚ŠæŠœã„ã¦ã¿ã‚‹ã€Pythonã€‘"
pubDate: 2025-07-18
categories: ["AI"]
tags: []
---

ã“ã‚“ã«ã¡ã¯ã€ãƒ•ãƒªãƒ¼ãƒ©ãƒ³ã‚¹ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã®å¤ªç”°é›…æ˜­ã§ã™ã€‚

## äººç‰©ç”»åƒã®åˆ‡ã‚ŠæŠœã

äººç‰©ç”»åƒã®åˆ‡ã‚ŠæŠœãã«ã¤ã„ã¦ã€Claude4sonnetã«èã„ã¦ã¿ã¾ã—ãŸã€‚

æ‰‹æ³•

äººç‰©ç²¾åº¦

å•†ç”¨åˆ©ç”¨

å‡¦ç†é€Ÿåº¦

PerSAM

95%

âœ… å®Œå…¨ç„¡æ–™

â­ï¸â­ï¸

MediaPipe Selfie

90%

âœ… å®Œå…¨ç„¡æ–™

â­ï¸â­ï¸â­ï¸â­ï¸â­ï¸

BiRefNet

85%

âœ… å®Œå…¨ç„¡æ–™

â­ï¸â­ï¸â­ï¸

SAM2

80%

âœ… å®Œå…¨ç„¡æ–™

â­ï¸â­ï¸

REMBG

75%

âœ… å®Œå…¨ç„¡æ–™

â­ï¸â­ï¸â­ï¸â­ï¸

RMBG 2.0

90%

âŒ å•†ç”¨å¥‘ç´„å¿…è¦

\-

PerSAMãŒæœ€ã‚‚å“è³ªã¯é«˜ã„ã‚ˆã†ã§ã™ã€‚é«ªã®æ¯›ã®ç´°éƒ¨ã¾ã§ä¸Šæ‰‹ãåˆ‡ã‚ŠæŠœã‘ã‚‹ã¨ã‹ã€‚ãŸã ãã®åˆ†å‡¦ç†é€Ÿåº¦ã«é›£ãŒã‚ã‚Šã¾ã™ã€‚ä¸€æ–¹MediaPipeã¯äººç‰©åˆ‡ã‚ŠæŠœãã«å¼·ãã€é€Ÿåº¦ã‚‚ã‚ã‚‹ã‚ˆã†ã§ã™ã€‚ä»Šå›ã¯MediaPipeã‚’ä½¿ç”¨ã—ã¾ã™ã€‚

## MediaPipeã‚’ä½¿ã£ã¦ã¿ã‚‹

ã¾ãšã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã™ã€‚

```
uv init
uv venv
uv add mediapipe
```

assetsãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ç”»åƒã‚’ã€outputsã«å‡ºåŠ›ã™ã‚‹ã‚³ãƒ¼ãƒ‰ã§ã™ã€‚AIã«ã‚ˆã‚‹Vibeã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã§ã™ã€‚ä¾¿åˆ©ã€‚

```python
import os
import cv2
import mediapipe as mp
from PIL import Image
import numpy as np
from pathlib import Path
from typing import Tuple, Optional


def remove_background(image: np.ndarray, mask: np.ndarray, background_color: Tuple[int, int, int] = (255, 255, 255),
                      smooth_edges: bool = True) -> np.ndarray:
    """
    èƒŒæ™¯ã‚’å‰Šé™¤ã¾ãŸã¯å˜è‰²èƒŒæ™¯ã«ç½®ãæ›ãˆã‚‹

    Args:
        image: å…¥åŠ›ç”»åƒ
        mask: ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒã‚¹ã‚¯
        background_color: èƒŒæ™¯è‰²ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼šç™½ï¼‰
        smooth_edges: ã‚¨ãƒƒã‚¸ã‚’æ»‘ã‚‰ã‹ã«ã™ã‚‹ã‹ã©ã†ã‹

    Returns:
        èƒŒæ™¯ã‚’å‰Šé™¤ã—ãŸç”»åƒ
    """
    if smooth_edges:
        # ã‚¨ãƒƒã‚¸ã‚’æ»‘ã‚‰ã‹ã«ã™ã‚‹å‡¦ç†
        mask = smooth_mask_edges(mask)

    mask_3ch = cv2.cvtColor(mask, cv2.COLOR_GRAY2RGB)
    mask_3ch = mask_3ch.astype(float) / 255.0

    background = np.full_like(image, background_color, dtype=np.uint8)
    result = image.astype(float) * mask_3ch + \
        background.astype(float) * (1 - mask_3ch)

    return result.astype(np.uint8)


def smooth_mask_edges(mask: np.ndarray, blur_size: int = 5, morph_size: int = 3) -> np.ndarray:
    """
    ãƒã‚¹ã‚¯ã®ã‚¨ãƒƒã‚¸ã‚’æ»‘ã‚‰ã‹ã«ã™ã‚‹

    Args:
        mask: å…¥åŠ›ãƒã‚¹ã‚¯
        blur_size: ã‚¬ã‚¦ã‚·ã‚¢ãƒ³ãƒ–ãƒ©ãƒ¼ã®ã‚µã‚¤ã‚º
        morph_size: ãƒ¢ãƒ«ãƒ•ã‚©ãƒ­ã‚¸ãƒ¼å¤‰æ›ã®ã‚«ãƒ¼ãƒãƒ«ã‚µã‚¤ã‚º

    Returns:
        æ»‘ã‚‰ã‹ã«ãªã£ãŸãƒã‚¹ã‚¯
    """
    # 1. ãƒ¢ãƒ«ãƒ•ã‚©ãƒ­ã‚¸ãƒ¼å¤‰æ›ã§ãƒã‚¤ã‚ºé™¤å»
    kernel = cv2.getStructuringElement(
        cv2.MORPH_ELLIPSE, (morph_size, morph_size))

    # Openingï¼ˆå°ã•ãªç©´ã‚’åŸ‹ã‚ã‚‹ï¼‰
    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)

    # Closingï¼ˆå°ã•ãªéš™é–“ã‚’åŸ‹ã‚ã‚‹ï¼‰
    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)

    # 2. ã‚¬ã‚¦ã‚·ã‚¢ãƒ³ãƒ–ãƒ©ãƒ¼ã§ã‚¨ãƒƒã‚¸ã‚’æ»‘ã‚‰ã‹ã«
    mask = cv2.GaussianBlur(mask, (blur_size, blur_size), 0)

    # 3. è»½ã„ã‚¨ãƒ­ãƒ¼ã‚¸ãƒ§ãƒ³ã§å¢ƒç•Œã‚’å°‘ã—å†…å´ã«
    erosion_kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (2, 2))
    mask = cv2.erode(mask, erosion_kernel, iterations=1)

    # 4. å†åº¦è»½ã„ãƒ–ãƒ©ãƒ¼
    mask = cv2.GaussianBlur(mask, (3, 3), 0)

    return mask


def process_background_removal(image: np.ndarray, selfie_segmentation, background_color: Tuple[int, int, int],
                               smooth_edges: bool = True) -> np.ndarray:
    """
    èƒŒæ™¯åˆ†é›¢å‡¦ç†ã‚’å®Ÿè¡Œã™ã‚‹

    Args:
        image: å…¥åŠ›ç”»åƒï¼ˆBGRï¼‰
        selfie_segmentation: MediaPipeã®èƒŒæ™¯åˆ†é›¢ãƒ¢ãƒ‡ãƒ«
        background_color: èƒŒæ™¯è‰²
        smooth_edges: ã‚¨ãƒƒã‚¸ã‚’æ»‘ã‚‰ã‹ã«ã™ã‚‹ã‹ã©ã†ã‹

    Returns:
        èƒŒæ™¯ãŒå‰Šé™¤ã•ã‚ŒãŸç”»åƒ
    """
    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    segmentation_results = selfie_segmentation.process(image_rgb)

    if segmentation_results.segmentation_mask is not None:
        mask = (segmentation_results.segmentation_mask >
                0.5).astype(np.uint8) * 255
        return remove_background(image, mask, background_color, smooth_edges)

    return image


def detect_faces(image: np.ndarray, face_detection):
    """
    é¡”æ¤œå‡ºã‚’å®Ÿè¡Œã™ã‚‹

    Args:
        image: å…¥åŠ›ç”»åƒï¼ˆBGRï¼‰
        face_detection: MediaPipeã®é¡”æ¤œå‡ºãƒ¢ãƒ‡ãƒ«

    Returns:
        æ¤œå‡ºçµæœ
    """
    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    return face_detection.process(image_rgb)


def calculate_face_crop_coords(detection, image_shape: Tuple[int, int], margin: float = 0.3) -> Tuple[int, int, int, int]:
    """
    é¡”ã®åˆ‡ã‚Šå‡ºã—åº§æ¨™ã‚’è¨ˆç®—ã™ã‚‹

    Args:
        detection: é¡”æ¤œå‡ºçµæœ
        image_shape: ç”»åƒã®ã‚µã‚¤ã‚º (height, width)
        margin: ãƒãƒ¼ã‚¸ãƒ³ã®å‰²åˆ

    Returns:
        (x1, y1, x2, y2) åˆ‡ã‚Šå‡ºã—åº§æ¨™
    """
    ih, iw = image_shape
    bboxC = detection.location_data.relative_bounding_box

    # ç›¸å¯¾åº§æ¨™ã‚’çµ¶å¯¾åº§æ¨™ã«å¤‰æ›
    x = int(bboxC.xmin * iw)
    y = int(bboxC.ymin * ih)
    w = int(bboxC.width * iw)
    h = int(bboxC.height * ih)

    # ãƒãƒ¼ã‚¸ãƒ³ã‚’è¿½åŠ 
    margin_x = int(w * margin)
    margin_y = int(h * margin)

    x1 = max(0, x - margin_x)
    y1 = max(0, y - margin_y)
    x2 = min(iw, x + w + margin_x)
    y2 = min(ih, y + h + margin_y)

    return x1, y1, x2, y2


def make_square_crop(x1: int, y1: int, x2: int, y2: int, image_shape: Tuple[int, int]) -> Tuple[int, int, int, int]:
    """
    åˆ‡ã‚Šå‡ºã—é ˜åŸŸã‚’æ­£æ–¹å½¢ã«èª¿æ•´ã™ã‚‹

    Args:
        x1, y1, x2, y2: å…ƒã®åˆ‡ã‚Šå‡ºã—åº§æ¨™
        image_shape: ç”»åƒã®ã‚µã‚¤ã‚º (height, width)

    Returns:
        (x1, y1, x2, y2) æ­£æ–¹å½¢ã«èª¿æ•´ã•ã‚ŒãŸåº§æ¨™
    """
    ih, iw = image_shape

    crop_w = x2 - x1
    crop_h = y2 - y1
    size = max(crop_w, crop_h)

    center_x = (x1 + x2) // 2
    center_y = (y1 + y2) // 2

    half_size = size // 2
    x1 = max(0, center_x - half_size)
    y1 = max(0, center_y - half_size)
    x2 = min(iw, center_x + half_size)
    y2 = min(ih, center_y + half_size)

    return x1, y1, x2, y2


def crop_and_save_face(image: np.ndarray, x1: int, y1: int, x2: int, y2: int,
                       output_path: Path, filename: str) -> bool:
    """
    é¡”ã‚’åˆ‡ã‚Šå‡ºã—ã¦ä¿å­˜ã™ã‚‹

    Args:
        image: å…¥åŠ›ç”»åƒ
        x1, y1, x2, y2: åˆ‡ã‚Šå‡ºã—åº§æ¨™
        output_path: å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        filename: å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«å

    Returns:
        ä¿å­˜æˆåŠŸã®å¯å¦
    """
    face_crop = image[y1:y2, x1:x2]

    if face_crop.size == 0:
        return False

    output_file_path = output_path / filename
    success = cv2.imwrite(str(output_file_path), face_crop)

    if success:
        print(
            f"ğŸ’¾ ä¿å­˜: {filename} (ã‚µã‚¤ã‚º: {face_crop.shape[1]}x{face_crop.shape[0]})")

    return success


def process_single_image(image_path: Path, face_detection, selfie_segmentation,
                         output_path: Path, remove_bg: bool, background_color: Tuple[int, int, int],
                         face_count: int, margin: float = 0.3, smooth_edges: bool = True) -> int:
    """
    1ã¤ã®ç”»åƒã‚’å‡¦ç†ã™ã‚‹

    Args:
        image_path: ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        face_detection: MediaPipeã®é¡”æ¤œå‡ºãƒ¢ãƒ‡ãƒ«
        selfie_segmentation: MediaPipeã®èƒŒæ™¯åˆ†é›¢ãƒ¢ãƒ‡ãƒ«
        output_path: å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        remove_bg: èƒŒæ™¯å‰Šé™¤ãƒ•ãƒ©ã‚°
        background_color: èƒŒæ™¯è‰²
        face_count: ç¾åœ¨ã®é¡”ã‚«ã‚¦ãƒ³ãƒˆ
        margin: ãƒãƒ¼ã‚¸ãƒ³ã®å‰²åˆ
        smooth_edges: ã‚¨ãƒƒã‚¸ã‚’æ»‘ã‚‰ã‹ã«ã™ã‚‹ã‹ã©ã†ã‹

    Returns:
        å‡¦ç†ã—ãŸé¡”ã®æ•°
    """
    print(f"ğŸ” å‡¦ç†ä¸­: {image_path.name}")

    # ç”»åƒã‚’èª­ã¿è¾¼ã¿
    image = cv2.imread(str(image_path))
    if image is None:
        print(f"âŒ ç”»åƒã‚’èª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸ: {image_path}")
        return 0

    # èƒŒæ™¯åˆ†é›¢å‡¦ç†
    processed_image = image.copy()
    if remove_bg:
        processed_image = process_background_removal(
            image, selfie_segmentation, background_color, smooth_edges)
        edge_status = "æ»‘ã‚‰ã‹ãªå¢ƒç•Œ" if smooth_edges else "æ¨™æº–å¢ƒç•Œ"
        print(f"âœ… èƒŒæ™¯ã‚’å‰Šé™¤ã—ã¾ã—ãŸ ({edge_status})")

    # é¡”æ¤œå‡ºå®Ÿè¡Œ
    results = detect_faces(image, face_detection)

    if not results.detections:
        print(f"âŒ é¡”ãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ: {image_path.name}")
        return 0

    print(f"âœ… {len(results.detections)} å€‹ã®é¡”ã‚’æ¤œå‡º")

    faces_saved = 0

    # æ¤œå‡ºã•ã‚ŒãŸå„é¡”ã‚’å‡¦ç†
    for i, detection in enumerate(results.detections):
        # åˆ‡ã‚Šå‡ºã—åº§æ¨™ã‚’è¨ˆç®—
        x1, y1, x2, y2 = calculate_face_crop_coords(
            detection, processed_image.shape[:2], margin)

        # æ­£æ–¹å½¢ã«èª¿æ•´
        x1, y1, x2, y2 = make_square_crop(
            x1, y1, x2, y2, processed_image.shape[:2])

        # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åç”Ÿæˆ
        bg_suffix = "_nobg" if remove_bg else ""
        filename = f"face_{face_count + faces_saved:04d}_{image_path.stem}_{i:02d}{bg_suffix}.jpg"

        # é¡”ã‚’åˆ‡ã‚Šå‡ºã—ã¦ä¿å­˜
        if crop_and_save_face(processed_image, x1, y1, x2, y2, output_path, filename):
            faces_saved += 1

    return faces_saved


def get_image_files(assets_path: Path) -> list:
    """
    ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒªã‚¹ãƒˆã‚’å–å¾—ã™ã‚‹

    Args:
        assets_path: ã‚¢ã‚»ãƒƒãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ‘ã‚¹

    Returns:
        ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒªã‚¹ãƒˆ
    """
    image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp'}

    return [
        path for path in assets_path.iterdir()
        if path.is_file() and path.suffix.lower() in image_extensions
    ]


def extract_faces_from_images(assets_dir: str = "assets", output_dir: str = "output",
                              remove_bg: bool = True, background_color: Tuple[int, int, int] = (255, 255, 255),
                              margin: float = 0.3, smooth_edges: bool = True):
    """
    assetsãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰ç”»åƒã‚’èª­ã¿è¾¼ã¿ã€mediapipeã§é¡”ã‚’æ¤œå‡ºãƒ»æŠ½å‡ºã—ã¦ä¿å­˜ã™ã‚‹

    Args:
        assets_dir: å…¥åŠ›ç”»åƒãŒã‚ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        output_dir: æŠ½å‡ºã—ãŸé¡”ç”»åƒã‚’ä¿å­˜ã™ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        remove_bg: èƒŒæ™¯ã‚’å‰Šé™¤ã™ã‚‹ã‹ã©ã†ã‹
        background_color: èƒŒæ™¯è‰²ï¼ˆRGBï¼‰
        margin: é¡”ã®å‘¨ã‚Šã®ãƒãƒ¼ã‚¸ãƒ³ï¼ˆå‰²åˆï¼‰
        smooth_edges: ã‚¨ãƒƒã‚¸ã‚’æ»‘ã‚‰ã‹ã«ã™ã‚‹ã‹ã©ã†ã‹
    """
    # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®å­˜åœ¨ç¢ºèªãƒ»ä½œæˆ
    assets_path = Path(assets_dir)
    output_path = Path(output_dir)

    if not assets_path.exists():
        print(f"âŒ {assets_dir} ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ã¾ã›ã‚“")
        return

    output_path.mkdir(exist_ok=True)
    print(f"ğŸ“ å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {output_path}")

    # ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒªã‚¹ãƒˆã‚’å–å¾—
    image_files = get_image_files(assets_path)
    if not image_files:
        print(f"âŒ {assets_dir} ã«ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return

    print(f"ğŸ“¸ å‡¦ç†å¯¾è±¡: {len(image_files)} å€‹ã®ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«")

    # MediaPipeã®åˆæœŸåŒ–
    mp_face_detection = mp.solutions.face_detection
    mp_selfie_segmentation = mp.solutions.selfie_segmentation

    face_count = 0

    with mp_face_detection.FaceDetection(
        model_selection=0,
        min_detection_confidence=0.5
    ) as face_detection, mp_selfie_segmentation.SelfieSegmentation(
        model_selection=1
    ) as selfie_segmentation:

        # å„ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†
        for image_path in image_files:
            faces_found = process_single_image(
                image_path, face_detection, selfie_segmentation,
                output_path, remove_bg, background_color, face_count, margin, smooth_edges
            )
            face_count += faces_found

    print(f"\nğŸ‰ å‡¦ç†å®Œäº†! åˆè¨ˆ {face_count} å€‹ã®é¡”ã‚’æŠ½å‡ºã—ã¾ã—ãŸ")
    print(f"ğŸ“ å‡ºåŠ›å…ˆ: {output_path}")
    if remove_bg:
        print(f"ğŸ¨ èƒŒæ™¯è‰²: RGB{background_color}")


def main():
    print("ğŸš€ MediaPipeé¡”æŠ½å‡ºãƒ„ãƒ¼ãƒ«ï¼ˆDreamBoothå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆç”¨ï¼‰")
    print("=" * 50)

    # è¨­å®š
    remove_background_flag = True  # èƒŒæ™¯ã‚’å‰Šé™¤ã™ã‚‹ã‹ã©ã†ã‹
    background_color = (255, 255, 255)  # ç™½èƒŒæ™¯ï¼ˆRGBï¼‰
    margin = 0.3  # é¡”ã®å‘¨ã‚Šã®ãƒãƒ¼ã‚¸ãƒ³ï¼ˆ30%ï¼‰
    smooth_edges = True  # ã‚¨ãƒƒã‚¸ã‚’æ»‘ã‚‰ã‹ã«ã™ã‚‹ã‹ã©ã†ã‹

    print(f"ğŸ¨ èƒŒæ™¯å‰Šé™¤: {'ON' if remove_background_flag else 'OFF'}")
    if remove_background_flag:
        print(f"ğŸ¨ èƒŒæ™¯è‰²: RGB{background_color}")
        print(f"ğŸ¨ ã‚¨ãƒƒã‚¸å‡¦ç†: {'æ»‘ã‚‰ã‹' if smooth_edges else 'æ¨™æº–'}")
    print(f"ğŸ¯ ãƒãƒ¼ã‚¸ãƒ³: {int(margin * 100)}%")

    # é¡”æŠ½å‡ºå®Ÿè¡Œ
    extract_faces_from_images(
        remove_bg=remove_background_flag,
        background_color=background_color,
        margin=margin,
        smooth_edges=smooth_edges
    )


if __name__ == "__main__":
    main()

```

å®Ÿè¡Œã—ã¾ã™ã€‚

```
uv run main.py
```

é¡”éƒ¨åˆ†ãŒåˆ‡ã‚ŠæŠœã‹ã‚Œã¾ã—ãŸã€‚åˆæœŸå®Ÿè¡Œæ™‚ã¯å°‘ã—æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã—ãŸãŒã€ï¼’å›ç›®ä»¥é™ã¯ä¸€ç¬ã§å®Œäº†ã™ã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã—ãŸã€‚